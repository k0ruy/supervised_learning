{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Ensemble Learning\n",
    "\n",
    "#### 1. Voting Classifier.\n",
    "\n",
    "(a) Load the MNIST dataset, which is a set of 70,000 small images (28x28 pixels)\n",
    "of digits handwritten. Each image is labeled with the digit it represents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "y = y.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "(b) Split it into a training set, a validation set, and a test set (e.g., use first 50,000\n",
    "instances for training, subsequent 10,000 for validation, and last 10,000 for\n",
    "testing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=10000, random_state=0)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=10000, random_state=0) # 0.25 x 0.8 = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "(c) Then train various classifiers, such as a Random Forest classifier, an Extra-\n",
    "Trees classifier, a Softmax Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "ExtraTreesClassifier(random_state=0)"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "rf = RandomForestClassifier(random_state=0)\n",
    "et = ExtraTreesClassifier(random_state=0)\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "rf.fit(X_train, y_train)\n",
    "et.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "I used KNeighborsClassifier since the soft max does not converge in a reasonable amount of time\n",
    "even if you use a scaler.\n",
    "\n",
    "(d) Next, try to combine them into an ensemble that outperforms them all on\n",
    "the validation set, using a soft or hard voting classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier 0.9679\n",
      "RandomForestClassifier 0.9679\n",
      "ExtraTreesClassifier 0.9706\n",
      "VotingClassifier 0.9729\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "import pandas as pd\n",
    "\n",
    "voting_clf = VotingClassifier(estimators=[('knn', knn), ('rf', rf), ('et', et)], voting='soft')\n",
    "\n",
    "#evaluate on the validation set\n",
    "val_predictions = pd.DataFrame()  # used in exerice 2.\n",
    "for clf in (knn, rf, et, voting_clf):\n",
    "  if clf == voting_clf:\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_val)\n",
    "  else:\n",
    "    y_pred = clf.predict(X_val)\n",
    "    val_predictions[clf.__class__.__name__] = y_pred\n",
    "  print(clf.__class__.__name__, accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) Once you have found one, try it on the test set. How much better does it\n",
    "perform compared to the individual classifiers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier 0.9718\n",
      "RandomForestClassifier 0.9675\n",
      "ExtraTreesClassifier 0.9681\n",
      "VotingClassifier 0.9768\n"
     ]
    }
   ],
   "source": [
    "test_predictions = pd.DataFrame() # used in exercise 2.\n",
    "for clf in (knn, rf, et, voting_clf):\n",
    "  if clf == voting_clf:\n",
    "    y_pred = clf.predict(X_test)\n",
    "  else:\n",
    "    y_pred = clf.predict(X_test)\n",
    "    test_predictions[clf.__class__.__name__] = y_pred\n",
    "  print(clf.__class__.__name__, accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 2. Stacking\n",
    "\n",
    "(a) Run the individual classifiers from the previous exercise to make predictions\n",
    "on the validation set, and create a new training set with the resulting predictions:\n",
    "each training instance is a vector containing the set of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(10000, 1)"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_blended = val_predictions\n",
    "y_train_blended = pd.DataFrame(y_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Train a classifier on this new training set.\n",
    "You have just trained a blender, and together with the classifiers they form\n",
    "a stacking ensemble!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "RandomForestClassifier(random_state=0)"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blended_rf  = RandomForestClassifier(random_state=0)\n",
    "blended_rf.fit(X_train_blended, np.ravel(y_train_blended))\n",
    "# since scikit-learn is expecting a flattened array, it would give a warning without using\n",
    "# ravel to flatten it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Now let’s evaluate the ensemble on the test set. For each image in the test\n",
    "set, make predictions with all your classifiers, then feed the predictions to\n",
    "the blender to get the ensemble’s predictions. How does it compare to the\n",
    "voting classifier you trained earlier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked score: 0.9708\n"
     ]
    }
   ],
   "source": [
    "X_test_blended = test_predictions\n",
    "y_test_blended = pd.DataFrame(y_test)\n",
    "y_pred =blended_rf.predict(X_test_blended)\n",
    "print(f\"Stacked score: {accuracy_score(y_pred, y_test_blended)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this case majority voting performed better compared to blended learning, although all models\n",
    "are working well."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-e1b38d0",
   "language": "python",
   "display_name": "PyCharm (Supervised Learning)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}