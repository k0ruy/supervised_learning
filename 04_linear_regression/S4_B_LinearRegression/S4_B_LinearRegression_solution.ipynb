{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "S4_B_LinearRegression_solution.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_LJvPXiP3qW"
      },
      "source": [
        "# Practice 4B: Linear Regression\n",
        "### Diabetes dataset : regression problem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmS-lcOWP6P5"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpzifKOEWxI9"
      },
      "source": [
        "# (1) Continue working on the Diabetes dataset exploited for Practice S_4A. In this case add to the dataset polynomial features of degree 3."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "8KUCspzbWg5V",
        "outputId": "06f946af-7d25-4810-8477-059dc4415dac"
      },
      "source": [
        "from sklearn.datasets import load_diabetes\n",
        "data = load_diabetes()\n",
        "\n",
        "df=pd.DataFrame(data=data.data, columns=data.feature_names)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>bp</th>\n",
              "      <th>s1</th>\n",
              "      <th>s2</th>\n",
              "      <th>s3</th>\n",
              "      <th>s4</th>\n",
              "      <th>s5</th>\n",
              "      <th>s6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.038076</td>\n",
              "      <td>0.050680</td>\n",
              "      <td>0.061696</td>\n",
              "      <td>0.021872</td>\n",
              "      <td>-0.044223</td>\n",
              "      <td>-0.034821</td>\n",
              "      <td>-0.043401</td>\n",
              "      <td>-0.002592</td>\n",
              "      <td>0.019908</td>\n",
              "      <td>-0.017646</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.001882</td>\n",
              "      <td>-0.044642</td>\n",
              "      <td>-0.051474</td>\n",
              "      <td>-0.026328</td>\n",
              "      <td>-0.008449</td>\n",
              "      <td>-0.019163</td>\n",
              "      <td>0.074412</td>\n",
              "      <td>-0.039493</td>\n",
              "      <td>-0.068330</td>\n",
              "      <td>-0.092204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.085299</td>\n",
              "      <td>0.050680</td>\n",
              "      <td>0.044451</td>\n",
              "      <td>-0.005671</td>\n",
              "      <td>-0.045599</td>\n",
              "      <td>-0.034194</td>\n",
              "      <td>-0.032356</td>\n",
              "      <td>-0.002592</td>\n",
              "      <td>0.002864</td>\n",
              "      <td>-0.025930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.089063</td>\n",
              "      <td>-0.044642</td>\n",
              "      <td>-0.011595</td>\n",
              "      <td>-0.036656</td>\n",
              "      <td>0.012191</td>\n",
              "      <td>0.024991</td>\n",
              "      <td>-0.036038</td>\n",
              "      <td>0.034309</td>\n",
              "      <td>0.022692</td>\n",
              "      <td>-0.009362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.005383</td>\n",
              "      <td>-0.044642</td>\n",
              "      <td>-0.036385</td>\n",
              "      <td>0.021872</td>\n",
              "      <td>0.003935</td>\n",
              "      <td>0.015596</td>\n",
              "      <td>0.008142</td>\n",
              "      <td>-0.002592</td>\n",
              "      <td>-0.031991</td>\n",
              "      <td>-0.046641</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        age       sex       bmi  ...        s4        s5        s6\n",
              "0  0.038076  0.050680  0.061696  ... -0.002592  0.019908 -0.017646\n",
              "1 -0.001882 -0.044642 -0.051474  ... -0.039493 -0.068330 -0.092204\n",
              "2  0.085299  0.050680  0.044451  ... -0.002592  0.002864 -0.025930\n",
              "3 -0.089063 -0.044642 -0.011595  ...  0.034309  0.022692 -0.009362\n",
              "4  0.005383 -0.044642 -0.036385  ... -0.002592 -0.031991 -0.046641\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gYoysdLZ800"
      },
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "# column SEX is the encoding of a boolean, it does not make sense to include it in the polynomials\n",
        "\n",
        "df_reduced = df.drop(columns=['sex'])\n",
        "\n",
        "poly = PolynomialFeatures(3, include_bias=False)\n",
        "df_reduced_poly= poly.fit_transform(df_reduced)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "lQqvFeKpbSY2",
        "outputId": "090941c2-8b9b-4170-8706-a62eb0d1653e"
      },
      "source": [
        "df_poly = pd.concat([df['sex'], pd.DataFrame(df_reduced_poly, columns=poly.get_feature_names_out())], axis=1)\n",
        "df_poly.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>bp</th>\n",
              "      <th>s1</th>\n",
              "      <th>s2</th>\n",
              "      <th>s3</th>\n",
              "      <th>s4</th>\n",
              "      <th>s5</th>\n",
              "      <th>s6</th>\n",
              "      <th>age^2</th>\n",
              "      <th>age bmi</th>\n",
              "      <th>age bp</th>\n",
              "      <th>age s1</th>\n",
              "      <th>age s2</th>\n",
              "      <th>age s3</th>\n",
              "      <th>age s4</th>\n",
              "      <th>age s5</th>\n",
              "      <th>age s6</th>\n",
              "      <th>bmi^2</th>\n",
              "      <th>bmi bp</th>\n",
              "      <th>bmi s1</th>\n",
              "      <th>bmi s2</th>\n",
              "      <th>bmi s3</th>\n",
              "      <th>bmi s4</th>\n",
              "      <th>bmi s5</th>\n",
              "      <th>bmi s6</th>\n",
              "      <th>bp^2</th>\n",
              "      <th>bp s1</th>\n",
              "      <th>bp s2</th>\n",
              "      <th>bp s3</th>\n",
              "      <th>bp s4</th>\n",
              "      <th>bp s5</th>\n",
              "      <th>bp s6</th>\n",
              "      <th>s1^2</th>\n",
              "      <th>s1 s2</th>\n",
              "      <th>s1 s3</th>\n",
              "      <th>s1 s4</th>\n",
              "      <th>s1 s5</th>\n",
              "      <th>s1 s6</th>\n",
              "      <th>...</th>\n",
              "      <th>s1 s4 s5</th>\n",
              "      <th>s1 s4 s6</th>\n",
              "      <th>s1 s5^2</th>\n",
              "      <th>s1 s5 s6</th>\n",
              "      <th>s1 s6^2</th>\n",
              "      <th>s2^3</th>\n",
              "      <th>s2^2 s3</th>\n",
              "      <th>s2^2 s4</th>\n",
              "      <th>s2^2 s5</th>\n",
              "      <th>s2^2 s6</th>\n",
              "      <th>s2 s3^2</th>\n",
              "      <th>s2 s3 s4</th>\n",
              "      <th>s2 s3 s5</th>\n",
              "      <th>s2 s3 s6</th>\n",
              "      <th>s2 s4^2</th>\n",
              "      <th>s2 s4 s5</th>\n",
              "      <th>s2 s4 s6</th>\n",
              "      <th>s2 s5^2</th>\n",
              "      <th>s2 s5 s6</th>\n",
              "      <th>s2 s6^2</th>\n",
              "      <th>s3^3</th>\n",
              "      <th>s3^2 s4</th>\n",
              "      <th>s3^2 s5</th>\n",
              "      <th>s3^2 s6</th>\n",
              "      <th>s3 s4^2</th>\n",
              "      <th>s3 s4 s5</th>\n",
              "      <th>s3 s4 s6</th>\n",
              "      <th>s3 s5^2</th>\n",
              "      <th>s3 s5 s6</th>\n",
              "      <th>s3 s6^2</th>\n",
              "      <th>s4^3</th>\n",
              "      <th>s4^2 s5</th>\n",
              "      <th>s4^2 s6</th>\n",
              "      <th>s4 s5^2</th>\n",
              "      <th>s4 s5 s6</th>\n",
              "      <th>s4 s6^2</th>\n",
              "      <th>s5^3</th>\n",
              "      <th>s5^2 s6</th>\n",
              "      <th>s5 s6^2</th>\n",
              "      <th>s6^3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.050680</td>\n",
              "      <td>0.038076</td>\n",
              "      <td>0.061696</td>\n",
              "      <td>0.021872</td>\n",
              "      <td>-0.044223</td>\n",
              "      <td>-0.034821</td>\n",
              "      <td>-0.043401</td>\n",
              "      <td>-0.002592</td>\n",
              "      <td>0.019908</td>\n",
              "      <td>-0.017646</td>\n",
              "      <td>0.001450</td>\n",
              "      <td>0.002349</td>\n",
              "      <td>0.000833</td>\n",
              "      <td>-0.001684</td>\n",
              "      <td>-0.001326</td>\n",
              "      <td>-0.001653</td>\n",
              "      <td>-0.000099</td>\n",
              "      <td>0.000758</td>\n",
              "      <td>-0.000672</td>\n",
              "      <td>0.003806</td>\n",
              "      <td>0.001349</td>\n",
              "      <td>-0.002728</td>\n",
              "      <td>-0.002148</td>\n",
              "      <td>-0.002678</td>\n",
              "      <td>-0.000160</td>\n",
              "      <td>0.001228</td>\n",
              "      <td>-0.001089</td>\n",
              "      <td>0.000478</td>\n",
              "      <td>-0.000967</td>\n",
              "      <td>-0.000762</td>\n",
              "      <td>-0.000949</td>\n",
              "      <td>-0.000057</td>\n",
              "      <td>0.000435</td>\n",
              "      <td>-0.000386</td>\n",
              "      <td>0.001956</td>\n",
              "      <td>0.001540</td>\n",
              "      <td>0.001919</td>\n",
              "      <td>0.000115</td>\n",
              "      <td>-0.000880</td>\n",
              "      <td>0.000780</td>\n",
              "      <td>...</td>\n",
              "      <td>2.282279e-06</td>\n",
              "      <td>-2.022932e-06</td>\n",
              "      <td>-1.752777e-05</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>-0.000014</td>\n",
              "      <td>-0.000042</td>\n",
              "      <td>-0.000053</td>\n",
              "      <td>-3.143080e-06</td>\n",
              "      <td>0.000024</td>\n",
              "      <td>-0.000021</td>\n",
              "      <td>-0.000066</td>\n",
              "      <td>-3.917557e-06</td>\n",
              "      <td>0.000030</td>\n",
              "      <td>-0.000027</td>\n",
              "      <td>-2.339893e-07</td>\n",
              "      <td>1.797024e-06</td>\n",
              "      <td>-0.000002</td>\n",
              "      <td>-1.380104e-05</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>-0.000011</td>\n",
              "      <td>-8.175128e-05</td>\n",
              "      <td>-4.882871e-06</td>\n",
              "      <td>0.000038</td>\n",
              "      <td>-0.000033</td>\n",
              "      <td>-2.916460e-07</td>\n",
              "      <td>2.239824e-06</td>\n",
              "      <td>-1.985301e-06</td>\n",
              "      <td>-1.720172e-05</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>-0.000014</td>\n",
              "      <td>-1.741954e-08</td>\n",
              "      <td>1.337810e-07</td>\n",
              "      <td>-1.185788e-07</td>\n",
              "      <td>-1.027431e-06</td>\n",
              "      <td>9.106785e-07</td>\n",
              "      <td>-8.071934e-07</td>\n",
              "      <td>7.890607e-06</td>\n",
              "      <td>-6.993957e-06</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>-5.494752e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.044642</td>\n",
              "      <td>-0.001882</td>\n",
              "      <td>-0.051474</td>\n",
              "      <td>-0.026328</td>\n",
              "      <td>-0.008449</td>\n",
              "      <td>-0.019163</td>\n",
              "      <td>0.074412</td>\n",
              "      <td>-0.039493</td>\n",
              "      <td>-0.068330</td>\n",
              "      <td>-0.092204</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.000097</td>\n",
              "      <td>0.000050</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>0.000036</td>\n",
              "      <td>-0.000140</td>\n",
              "      <td>0.000074</td>\n",
              "      <td>0.000129</td>\n",
              "      <td>0.000174</td>\n",
              "      <td>0.002650</td>\n",
              "      <td>0.001355</td>\n",
              "      <td>0.000435</td>\n",
              "      <td>0.000986</td>\n",
              "      <td>-0.003830</td>\n",
              "      <td>0.002033</td>\n",
              "      <td>0.003517</td>\n",
              "      <td>0.004746</td>\n",
              "      <td>0.000693</td>\n",
              "      <td>0.000222</td>\n",
              "      <td>0.000505</td>\n",
              "      <td>-0.001959</td>\n",
              "      <td>0.001040</td>\n",
              "      <td>0.001799</td>\n",
              "      <td>0.002428</td>\n",
              "      <td>0.000071</td>\n",
              "      <td>0.000162</td>\n",
              "      <td>-0.000629</td>\n",
              "      <td>0.000334</td>\n",
              "      <td>0.000577</td>\n",
              "      <td>0.000779</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.279950e-05</td>\n",
              "      <td>-3.076561e-05</td>\n",
              "      <td>-3.944670e-05</td>\n",
              "      <td>-0.000053</td>\n",
              "      <td>-0.000072</td>\n",
              "      <td>-0.000007</td>\n",
              "      <td>0.000027</td>\n",
              "      <td>-1.450330e-05</td>\n",
              "      <td>-0.000025</td>\n",
              "      <td>-0.000034</td>\n",
              "      <td>-0.000106</td>\n",
              "      <td>5.631654e-05</td>\n",
              "      <td>0.000097</td>\n",
              "      <td>0.000131</td>\n",
              "      <td>-2.988958e-05</td>\n",
              "      <td>-5.171367e-05</td>\n",
              "      <td>-0.000070</td>\n",
              "      <td>-8.947275e-05</td>\n",
              "      <td>-0.000121</td>\n",
              "      <td>-0.000163</td>\n",
              "      <td>4.120228e-04</td>\n",
              "      <td>-2.186781e-04</td>\n",
              "      <td>-0.000378</td>\n",
              "      <td>-0.000511</td>\n",
              "      <td>1.160617e-04</td>\n",
              "      <td>2.008050e-04</td>\n",
              "      <td>2.709660e-04</td>\n",
              "      <td>3.474242e-04</td>\n",
              "      <td>0.000469</td>\n",
              "      <td>0.000633</td>\n",
              "      <td>-6.159891e-05</td>\n",
              "      <td>-1.065758e-04</td>\n",
              "      <td>-1.438132e-04</td>\n",
              "      <td>-1.843928e-04</td>\n",
              "      <td>-2.488193e-04</td>\n",
              "      <td>-3.357564e-04</td>\n",
              "      <td>-3.190284e-04</td>\n",
              "      <td>-4.304965e-04</td>\n",
              "      <td>-0.000581</td>\n",
              "      <td>-7.838807e-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.050680</td>\n",
              "      <td>0.085299</td>\n",
              "      <td>0.044451</td>\n",
              "      <td>-0.005671</td>\n",
              "      <td>-0.045599</td>\n",
              "      <td>-0.034194</td>\n",
              "      <td>-0.032356</td>\n",
              "      <td>-0.002592</td>\n",
              "      <td>0.002864</td>\n",
              "      <td>-0.025930</td>\n",
              "      <td>0.007276</td>\n",
              "      <td>0.003792</td>\n",
              "      <td>-0.000484</td>\n",
              "      <td>-0.003890</td>\n",
              "      <td>-0.002917</td>\n",
              "      <td>-0.002760</td>\n",
              "      <td>-0.000221</td>\n",
              "      <td>0.000244</td>\n",
              "      <td>-0.002212</td>\n",
              "      <td>0.001976</td>\n",
              "      <td>-0.000252</td>\n",
              "      <td>-0.002027</td>\n",
              "      <td>-0.001520</td>\n",
              "      <td>-0.001438</td>\n",
              "      <td>-0.000115</td>\n",
              "      <td>0.000127</td>\n",
              "      <td>-0.001153</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>0.000259</td>\n",
              "      <td>0.000194</td>\n",
              "      <td>0.000183</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>-0.000016</td>\n",
              "      <td>0.000147</td>\n",
              "      <td>0.002079</td>\n",
              "      <td>0.001559</td>\n",
              "      <td>0.001475</td>\n",
              "      <td>0.000118</td>\n",
              "      <td>-0.000131</td>\n",
              "      <td>0.001182</td>\n",
              "      <td>...</td>\n",
              "      <td>3.385141e-07</td>\n",
              "      <td>-3.065115e-06</td>\n",
              "      <td>-3.739694e-07</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>-0.000031</td>\n",
              "      <td>-0.000040</td>\n",
              "      <td>-0.000038</td>\n",
              "      <td>-3.031032e-06</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>-0.000030</td>\n",
              "      <td>-0.000036</td>\n",
              "      <td>-2.868063e-06</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>-0.000029</td>\n",
              "      <td>-2.297807e-07</td>\n",
              "      <td>2.538475e-07</td>\n",
              "      <td>-0.000002</td>\n",
              "      <td>-2.804350e-07</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>-0.000023</td>\n",
              "      <td>-3.387363e-05</td>\n",
              "      <td>-2.713856e-06</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>-0.000027</td>\n",
              "      <td>-2.174261e-07</td>\n",
              "      <td>2.401989e-07</td>\n",
              "      <td>-2.174909e-06</td>\n",
              "      <td>-2.653569e-07</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>-0.000022</td>\n",
              "      <td>-1.741954e-08</td>\n",
              "      <td>1.924403e-08</td>\n",
              "      <td>-1.742473e-07</td>\n",
              "      <td>-2.125961e-08</td>\n",
              "      <td>1.924976e-07</td>\n",
              "      <td>-1.742992e-06</td>\n",
              "      <td>2.348630e-08</td>\n",
              "      <td>-2.126594e-07</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>-1.743511e-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.044642</td>\n",
              "      <td>-0.089063</td>\n",
              "      <td>-0.011595</td>\n",
              "      <td>-0.036656</td>\n",
              "      <td>0.012191</td>\n",
              "      <td>0.024991</td>\n",
              "      <td>-0.036038</td>\n",
              "      <td>0.034309</td>\n",
              "      <td>0.022692</td>\n",
              "      <td>-0.009362</td>\n",
              "      <td>0.007932</td>\n",
              "      <td>0.001033</td>\n",
              "      <td>0.003265</td>\n",
              "      <td>-0.001086</td>\n",
              "      <td>-0.002226</td>\n",
              "      <td>0.003210</td>\n",
              "      <td>-0.003056</td>\n",
              "      <td>-0.002021</td>\n",
              "      <td>0.000834</td>\n",
              "      <td>0.000134</td>\n",
              "      <td>0.000425</td>\n",
              "      <td>-0.000141</td>\n",
              "      <td>-0.000290</td>\n",
              "      <td>0.000418</td>\n",
              "      <td>-0.000398</td>\n",
              "      <td>-0.000263</td>\n",
              "      <td>0.000109</td>\n",
              "      <td>0.001344</td>\n",
              "      <td>-0.000447</td>\n",
              "      <td>-0.000916</td>\n",
              "      <td>0.001321</td>\n",
              "      <td>-0.001258</td>\n",
              "      <td>-0.000832</td>\n",
              "      <td>0.000343</td>\n",
              "      <td>0.000149</td>\n",
              "      <td>0.000305</td>\n",
              "      <td>-0.000439</td>\n",
              "      <td>0.000418</td>\n",
              "      <td>0.000277</td>\n",
              "      <td>-0.000114</td>\n",
              "      <td>...</td>\n",
              "      <td>9.490814e-06</td>\n",
              "      <td>-3.915568e-06</td>\n",
              "      <td>6.277264e-06</td>\n",
              "      <td>-0.000003</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>-0.000023</td>\n",
              "      <td>2.142690e-05</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>-0.000006</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>-3.089857e-05</td>\n",
              "      <td>-0.000020</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>2.941637e-05</td>\n",
              "      <td>1.945611e-05</td>\n",
              "      <td>-0.000008</td>\n",
              "      <td>1.286835e-05</td>\n",
              "      <td>-0.000005</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>-4.680222e-05</td>\n",
              "      <td>4.455714e-05</td>\n",
              "      <td>0.000029</td>\n",
              "      <td>-0.000012</td>\n",
              "      <td>-4.241974e-05</td>\n",
              "      <td>-2.805660e-05</td>\n",
              "      <td>1.157514e-05</td>\n",
              "      <td>-1.855675e-05</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>-0.000003</td>\n",
              "      <td>4.038488e-05</td>\n",
              "      <td>2.671073e-05</td>\n",
              "      <td>-1.101989e-05</td>\n",
              "      <td>1.766659e-05</td>\n",
              "      <td>-7.288598e-06</td>\n",
              "      <td>3.007013e-06</td>\n",
              "      <td>1.168476e-05</td>\n",
              "      <td>-4.820709e-06</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>-8.205283e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.044642</td>\n",
              "      <td>0.005383</td>\n",
              "      <td>-0.036385</td>\n",
              "      <td>0.021872</td>\n",
              "      <td>0.003935</td>\n",
              "      <td>0.015596</td>\n",
              "      <td>0.008142</td>\n",
              "      <td>-0.002592</td>\n",
              "      <td>-0.031991</td>\n",
              "      <td>-0.046641</td>\n",
              "      <td>0.000029</td>\n",
              "      <td>-0.000196</td>\n",
              "      <td>0.000118</td>\n",
              "      <td>0.000021</td>\n",
              "      <td>0.000084</td>\n",
              "      <td>0.000044</td>\n",
              "      <td>-0.000014</td>\n",
              "      <td>-0.000172</td>\n",
              "      <td>-0.000251</td>\n",
              "      <td>0.001324</td>\n",
              "      <td>-0.000796</td>\n",
              "      <td>-0.000143</td>\n",
              "      <td>-0.000567</td>\n",
              "      <td>-0.000296</td>\n",
              "      <td>0.000094</td>\n",
              "      <td>0.001164</td>\n",
              "      <td>0.001697</td>\n",
              "      <td>0.000478</td>\n",
              "      <td>0.000086</td>\n",
              "      <td>0.000341</td>\n",
              "      <td>0.000178</td>\n",
              "      <td>-0.000057</td>\n",
              "      <td>-0.000700</td>\n",
              "      <td>-0.001020</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.000061</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>-0.000010</td>\n",
              "      <td>-0.000126</td>\n",
              "      <td>-0.000184</td>\n",
              "      <td>...</td>\n",
              "      <td>3.263181e-07</td>\n",
              "      <td>4.757447e-07</td>\n",
              "      <td>4.027134e-06</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>-6.305407e-07</td>\n",
              "      <td>-0.000008</td>\n",
              "      <td>-0.000011</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>-3.291786e-07</td>\n",
              "      <td>-0.000004</td>\n",
              "      <td>-0.000006</td>\n",
              "      <td>1.048033e-07</td>\n",
              "      <td>1.293391e-06</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>1.596191e-05</td>\n",
              "      <td>0.000023</td>\n",
              "      <td>0.000034</td>\n",
              "      <td>5.397674e-07</td>\n",
              "      <td>-1.718502e-07</td>\n",
              "      <td>-0.000002</td>\n",
              "      <td>-0.000003</td>\n",
              "      <td>5.471335e-08</td>\n",
              "      <td>6.752247e-07</td>\n",
              "      <td>9.844216e-07</td>\n",
              "      <td>8.333036e-06</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>-1.741954e-08</td>\n",
              "      <td>-2.149768e-07</td>\n",
              "      <td>-3.134184e-07</td>\n",
              "      <td>-2.653057e-06</td>\n",
              "      <td>-3.867937e-06</td>\n",
              "      <td>-5.639132e-06</td>\n",
              "      <td>-3.274173e-05</td>\n",
              "      <td>-4.773472e-05</td>\n",
              "      <td>-0.000070</td>\n",
              "      <td>-1.014612e-04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 220 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        sex       age       bmi  ...       s5^2 s6   s5 s6^2          s6^3\n",
              "0  0.050680  0.038076  0.061696  ... -6.993957e-06  0.000006 -5.494752e-06\n",
              "1 -0.044642 -0.001882 -0.051474  ... -4.304965e-04 -0.000581 -7.838807e-04\n",
              "2  0.050680  0.085299  0.044451  ... -2.126594e-07  0.000002 -1.743511e-05\n",
              "3 -0.044642 -0.089063 -0.011595  ... -4.820709e-06  0.000002 -8.205283e-07\n",
              "4 -0.044642  0.005383 -0.036385  ... -4.773472e-05 -0.000070 -1.014612e-04\n",
              "\n",
              "[5 rows x 220 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1W6JfhO3cqMU"
      },
      "source": [
        "X=df_poly.values\n",
        "y=data.target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwqpAdBmc69G"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IAIw64KXRGN"
      },
      "source": [
        "# (2) Use the Sklearn implementation of Linear Regression to find the best $\\theta$ vector. Provide an interpretation of each hypothesis parameter in the trained model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SU3sfFUgcvQc"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9aVb853dp9n"
      },
      "source": [
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(X_train, y_train)\n",
        "y_predict=lin_reg.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qsalmishc-kc",
        "outputId": "569437ea-faab-45b7-939a-e10537ac7063"
      },
      "source": [
        "print(\"test MSE={}\".format(mean_squared_error(y_test, y_predict)))\n",
        "print(\"test R2={}\".format(r2_score(y_test, y_predict)))\n",
        "\n",
        "print(\"train MSE={}\".format(mean_squared_error(y_train, lin_reg.predict(X_train))))\n",
        "print(\"train R2={}\".format(r2_score(y_train, lin_reg.predict(X_train))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test MSE=68755.21542653156\n",
            "test R2=-12.020539931916494\n",
            "train MSE=956.544254583741\n",
            "train R2=0.8453124212116909\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzbY5aNLdzEo",
        "outputId": "6bf49c23-7375-40ad-ff52-5e68c06bb128"
      },
      "source": [
        "len(lin_reg.coef_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "220"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4i3CT-_d7YN"
      },
      "source": [
        "Corfficients are 220, it is quite difficult to understand the trained hypotesis parameters. The model is difficult to interpret. From the $R^2$ score we can see that the model is performing quite well in the training set bu very bad in the test set, this means the model is overfitting the data. This might be given by the complexity of the model (model with high variance). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kD0-KX6LXYqL"
      },
      "source": [
        "#(3) Train a Linear Regression model with Ridge regularization. Iterate over different values of $\\alpha$ in order to find the value which minimize the test-MSE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXITO61uegMS"
      },
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "Fw2knKhJgrwD",
        "outputId": "4bdb9d40-19f8-4830-96c7-2abb8585302f"
      },
      "source": [
        "alphas=[0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.008, 0.1, 0.2]\n",
        "mse_values=[]\n",
        "\n",
        "for alpha in alphas:\n",
        "  ridge_model = Ridge(alpha=alpha)\n",
        "  ridge_model.fit(X_train, y_train)\n",
        "  y_predict=ridge_model.predict(X_test)\n",
        "  mse_values.append(mean_squared_error(y_test, y_predict))\n",
        "\n",
        "plt.scatter(alphas, mse_values)\n",
        "plt.xlabel('alpha')\n",
        "plt.ylabel(\"MSE\")\n",
        "\n",
        "print(\"Minimum test-MSE = {}\".format(np.min(mse_values)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum test-MSE = 2756.76243336323\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ngd6HvbciAYO"
      },
      "source": [
        "The value of $\\alpha$ that minimises the MSE on the test set os $\\alpha = 0.005$. The related MSE is $3017$, which is much lower than the value calculated with the Linear Regression without regularization ($9517292$)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7UZuFa7XgCH"
      },
      "source": [
        "# (4) Train a Linear Regression model with Lasso regularization. Iterate over different values of $\\alpha$ in order to find the value which minimize the test-MSE. Provide an interpretation of each hypothesis parameter in the trained model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8NJSR_fWkxq"
      },
      "source": [
        "from sklearn.linear_model import Lasso"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "id": "ERx7pzqSjFg9",
        "outputId": "b408b03b-0985-440c-c08d-9fbd8b88077b"
      },
      "source": [
        "alphas=[0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.008, 0.1, 0.2]\n",
        "mse_values=[]\n",
        "\n",
        "for alpha in alphas:\n",
        "  lasso_model = Lasso(alpha=alpha)\n",
        "  lasso_model.fit(X_train, y_train)\n",
        "  y_predict=lasso_model.predict(X_test)\n",
        "  mse_values.append(mean_squared_error(y_test, y_predict))\n",
        "\n",
        "plt.scatter(alphas, mse_values)\n",
        "plt.xlabel('alpha')\n",
        "plt.ylabel(\"MSE\")\n",
        "\n",
        "print(\"Minimum test-MSE = {}\".format(np.min(mse_values)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.343e+05, tolerance: 1.911e+02\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.661e+04, tolerance: 1.911e+02\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum test-MSE = 2751.2081175057997\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5t7MaBYpjZIZ"
      },
      "source": [
        "The value of $\\alpha$ that minimises the MSE on the test set os $\\alpha = 0.008$. The related MSE is $2977$, which is slightly lower than the value calculated with the Ridge Regression ($3017$)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVBA64QyjYmS",
        "outputId": "7c120553-3362-443b-cf16-8d5fb3536191"
      },
      "source": [
        "best_lasso_model = Lasso(alpha=0.008)\n",
        "best_lasso_model.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Lasso(alpha=0.008)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvN9y43AjMZV",
        "outputId": "4f752391-89e8-45fa-9794-b71cec9a044b"
      },
      "source": [
        "sum((best_lasso_model.coef_!=0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nv3T1XtelLvd"
      },
      "source": [
        "The number of non zero features is 18. These features have the highest relevance to the task which we are performing. The model is more interpretable than the model trained on 220 features. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6g-ZCAEgkLQT"
      },
      "source": [
        "all_columns = pd.DataFrame(df_poly.columns, columns=[\"columns\"])\n",
        "non_zero_columns=all_columns[best_lasso_model.coef_!=0]\n",
        "#non_zero_columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofsNxpd5kqoj"
      },
      "source": [
        "all_coeff = pd.DataFrame(best_lasso_model.coef_, columns=[\"coeff\"])\n",
        "non_zero_coeff=all_coeff[best_lasso_model.coef_!=0]\n",
        "#non_zero_coeff"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9qkFgsTlw0I",
        "outputId": "c61a2253-e42e-442f-dace-f192b08effe4"
      },
      "source": [
        "parameters=pd.concat([non_zero_columns, non_zero_coeff], axis=1)\n",
        "print(parameters)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   columns        coeff\n",
            "0      sex  -160.457067\n",
            "1      age    87.536472\n",
            "2      bmi   395.050207\n",
            "3       bp   373.117291\n",
            "4       s1  -399.573760\n",
            "5       s2   192.342286\n",
            "6       s3  -112.936934\n",
            "7       s4    80.390203\n",
            "8       s5   657.243019\n",
            "9       s6    17.148102\n",
            "18  age s6    73.083841\n",
            "19   bmi^2  1015.108449\n",
            "20  bmi bp  1402.606838\n",
            "54    s6^2  1151.629896\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "HUV6LAPAl-Vz",
        "outputId": "821b8f0e-1605-4f5f-9b8c-4a044f2b7916"
      },
      "source": [
        "parameters.sort_values(by=[\"coeff\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>columns</th>\n",
              "      <th>coeff</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>s1</td>\n",
              "      <td>-399.573760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sex</td>\n",
              "      <td>-160.457067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>s3</td>\n",
              "      <td>-112.936934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>s6</td>\n",
              "      <td>17.148102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>age s6</td>\n",
              "      <td>73.083841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>s4</td>\n",
              "      <td>80.390203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>age</td>\n",
              "      <td>87.536472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>s2</td>\n",
              "      <td>192.342286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bp</td>\n",
              "      <td>373.117291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>bmi</td>\n",
              "      <td>395.050207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>s5</td>\n",
              "      <td>657.243019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>bmi^2</td>\n",
              "      <td>1015.108449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>s6^2</td>\n",
              "      <td>1151.629896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>bmi bp</td>\n",
              "      <td>1402.606838</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   columns        coeff\n",
              "4       s1  -399.573760\n",
              "0      sex  -160.457067\n",
              "6       s3  -112.936934\n",
              "9       s6    17.148102\n",
              "18  age s6    73.083841\n",
              "7       s4    80.390203\n",
              "1      age    87.536472\n",
              "5       s2   192.342286\n",
              "3       bp   373.117291\n",
              "2      bmi   395.050207\n",
              "8       s5   657.243019\n",
              "19   bmi^2  1015.108449\n",
              "54    s6^2  1151.629896\n",
              "20  bmi bp  1402.606838"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdfhyOfGrnra"
      },
      "source": [
        "Features having highest himpact on the final prediction are `[\"bmi bp\", \"s6^2\", \"bmi^2\", \"s5\"]`"
      ]
    }
  ]
}