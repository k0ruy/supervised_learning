{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n4-4SGNvfo24"
   },
   "source": [
    "# Nonparametric regression\n",
    "- Linear Regression assumes a linear relationship between the dependent and independent variables, which is rarely the case in reality.\n",
    "- Polynomial Regression generates better results (most of the time). But using Polynomial Regression on datasets with high variability chances to result in over-fitting.\n",
    "- Nonlinear regression: combination of linear/polynomial functions to fit the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sJG1NMa4W94Z",
    "outputId": "8746ba0e-f6d4-48a8-d2f7-66355b244375"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JemgRy2Oftnr"
   },
   "source": [
    "We are going to use the wage dataset. In detail information about Age and Wage of various employes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgZG8gewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwoKICAgICAgbGV0IHBlcmNlbnREb25lID0gZmlsZURhdGEuYnl0ZUxlbmd0aCA9PT0gMCA/CiAgICAgICAgICAxMDAgOgogICAgICAgICAgTWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCk7CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPSBgJHtwZXJjZW50RG9uZX0lIGRvbmVgOwoKICAgIH0gd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCk7CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "id": "Hs6y3PnsXCF1",
    "outputId": "62017906-310c-43c1-9d40-c141abd367d0"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9412/2535520808.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0muploaded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "nZmbLfPJXEl5"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'uploaded' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9412/862447517.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muploaded\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Wage.csv'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'uploaded' is not defined"
     ]
    }
   ],
   "source": [
    "import io\n",
    "data = pd.read_csv(io.BytesIO(uploaded['Wage.csv']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JiO0a6GsXL3H"
   },
   "outputs": [],
   "source": [
    "data_x = data['age']\n",
    "data_y = data['wage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NUdFAFBvXcJ2"
   },
   "outputs": [],
   "source": [
    "# Dividing data into train and validation datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(data_x, data_y, test_size=0.33, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "YxR7N8h7XUAh",
    "outputId": "0f1b295d-2c7b-4dac-e98d-715b5635d5eb"
   },
   "outputs": [],
   "source": [
    "# Visualize the relationship b/w age and wage\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(train_x, train_y, facecolor='None', edgecolor='k', alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lRsoksLgXnVy"
   },
   "source": [
    "QUESTION: is the data positively, negatively or zero correlated?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H42O8ybPXzYG"
   },
   "source": [
    "## Regression Splines\n",
    "Instead of building one model for the entire dataset, a regression spline technique divides the dataset into multiple bins and fits each bin with a separate model.\n",
    "We divide the distribution of the data into separate portions and fit linear or low degree polynomial functions on each of these portions.\n",
    "\n",
    "The points where the division occurs are called **Knots**. \n",
    "\n",
    "Functions which we can use for modelling each piece/bin are known as **Piecewise functions**. There are various piecewise functions that we can use to fit these individual bins."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_sVQRwI1YkV4"
   },
   "source": [
    "### Piecewise Step Function \n",
    "Step function is a function which remains constant within the interval. We can fit individual step functions to each of the divided portions in order to avoid imposing a global structure. Here we break the range of X into bins, and fit a different constant in each bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8zWSIaOgXjNP",
    "outputId": "2f4e65b2-024c-4512-859b-ff9768a3d8d7"
   },
   "outputs": [],
   "source": [
    "# Dividing the data into 4 bins\n",
    "df_cut, bins = pd.cut(train_x, 4, retbins=True, right=True)\n",
    "df_cut.value_counts(sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vy65sfCfZAPV"
   },
   "source": [
    "We create cut points C1 , C2, . . . , Ck  in the range of X, and then construct K  + 1 new variables. For a given value of X, at most only one of C1, C2, . . ., CK  can be non-zero, as X can only lie in any one of the bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "wOsD7qlxZNNK",
    "outputId": "36fefd2e-6cab-4d6b-834e-f36961b7db72"
   },
   "outputs": [],
   "source": [
    "df_steps = pd.concat([train_x, df_cut, train_y], keys=['age','age_cuts','wage'], axis=1)\n",
    "\n",
    "# Create dummy variables for the age groups\n",
    "df_steps_dummies = pd.get_dummies(df_cut)\n",
    "df_steps_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GamADVuoZbPw"
   },
   "outputs": [],
   "source": [
    "# Fitting Generalised linear models\n",
    "fit3 = sm.GLM(df_steps.wage, df_steps_dummies).fit()\n",
    "\n",
    "# Binning validation set into same 4 bins\n",
    "bin_mapping = np.digitize(valid_x, bins) \n",
    "X_valid = pd.get_dummies(bin_mapping)\n",
    "\n",
    "# Removing any outliers\n",
    "X_valid = pd.get_dummies(bin_mapping).drop([5], axis=1)\n",
    "\n",
    "# Prediction\n",
    "pred2 = fit3.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bj5jiHxfaUWc",
    "outputId": "5bdc7d76-2833-4d2b-ac3d-b51b142901e9"
   },
   "outputs": [],
   "source": [
    "# Calculating RMSE\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from math import sqrt \n",
    "\n",
    "rms = sqrt(mean_squared_error(valid_y, pred2)) \n",
    "print(rms) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C6NFFXBiZ3Xc"
   },
   "outputs": [],
   "source": [
    "# We will plot the graph for 70 observations only\n",
    "xp = np.linspace(valid_x.min(),valid_x.max()-1,70) \n",
    "\n",
    "bin_mapping = np.digitize(xp, bins) \n",
    "\n",
    "X_valid_2 = pd.get_dummies(bin_mapping) \n",
    "\n",
    "pred2 = fit3.predict(X_valid_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "id": "2zQ8gcmlaaSK",
    "outputId": "a3b4821f-8300-4008-8799-a21f516bf40e"
   },
   "outputs": [],
   "source": [
    "# Visualisation\n",
    "fig, (ax1) = plt.subplots(1,1, figsize=(12,5))\n",
    "fig.suptitle('Piecewise Constant', fontsize=14)\n",
    "\n",
    "# Scatter plot with polynomial regression line\n",
    "ax1.scatter(train_x, train_y, facecolor='None', edgecolor='k', alpha=0.3)\n",
    "ax1.plot(xp, pred2, c='b')\n",
    "\n",
    "ax1.set_xlabel('age')\n",
    "ax1.set_ylabel('wage')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "156t2lX3asVb"
   },
   "source": [
    "Binning has its obvious conceptual issues. Most prominently, we expect most phenomena we study to vary continuously with inputs. Binned regression does not create continuous functions of the predictor, so in most cases we would expect no relationship between the input and output.\n",
    "\n",
    "For example, in the above graph, we can see that the first bin clearly misses the increasing trend of wage with age."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ljgZ-Fea3Vz"
   },
   "source": [
    "### Piecewise Polynomials\n",
    "There are various constraints that we need to follow.\n",
    "1. The polynomials on either side of a knot should be continuous at the knot.\n",
    "2. The first derivative of both the polynomials must be same at the knot (to smoothen the polinomials at the knots)\n",
    "3. The double derivatives of both the polynomials at a knot must be same.\n",
    "\n",
    "Such a piecewise polynomial of degree m with m-1 continuous derivatives is called a Spline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dhGnTIbfa2Na",
    "outputId": "37173db0-ec03-4596-d688-4ab6b059aab5"
   },
   "outputs": [],
   "source": [
    "from patsy import dmatrix\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Generating cubic spline with 3 knots at 25, 40 and 60 (basis spline)\n",
    "transformed_x = dmatrix(\"bs(train, knots=(25,40,60), degree=3, include_intercept=False)\", {\"train\": train_x},return_type='dataframe')\n",
    "\n",
    "# Fitting Generalised linear model on transformed dataset\n",
    "fit1 = sm.GLM(train_y, transformed_x).fit()\n",
    "\n",
    "# Generating cubic spline with 4 knots\n",
    "transformed_x2 = dmatrix(\"bs(train, knots=(25,40,50,65),degree =3, include_intercept=False)\", {\"train\": train_x}, return_type='dataframe')\n",
    "\n",
    "# Fitting Generalised linear model on transformed dataset\n",
    "fit2 = sm.GLM(train_y, transformed_x2).fit()\n",
    "\n",
    "# Predictions on both splines\n",
    "pred1 = fit1.predict(dmatrix(\"bs(valid, knots=(25,40,60), include_intercept=False)\", {\"valid\": valid_x}, return_type='dataframe'))\n",
    "pred2 = fit2.predict(dmatrix(\"bs(valid, knots=(25,40,50,65),degree =3, include_intercept=False)\", {\"valid\": valid_x}, return_type='dataframe'))\n",
    "\n",
    "# Calculating RMSE values\n",
    "rms1 = sqrt(mean_squared_error(valid_y, pred1))\n",
    "print(rms1)\n",
    "\n",
    "rms2 = sqrt(mean_squared_error(valid_y, pred2))\n",
    "print(rms2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "iiy4HFkXmrrv",
    "outputId": "581705d3-52b0-4ff2-8f82-14dcf7a45c21"
   },
   "outputs": [],
   "source": [
    "# We will plot the graph for 70 observations only\n",
    "xp = np.linspace(valid_x.min(),valid_x.max(),70)\n",
    "\n",
    "# Make some predictions\n",
    "pred1 = fit1.predict(dmatrix(\"bs(xp, knots=(25,40,60), include_intercept=False)\", {\"xp\": xp}, return_type='dataframe'))\n",
    "pred2 = fit2.predict(dmatrix(\"bs(xp, knots=(25,40,50,65),degree =3, include_intercept=False)\", {\"xp\": xp}, return_type='dataframe'))\n",
    "\n",
    "# Plot the splines and error bands\n",
    "plt.scatter(data.age, data.wage, facecolor='None', edgecolor='k', alpha=0.1)\n",
    "plt.plot(xp, pred1, label='Specifying degree =3 with 3 knots')\n",
    "plt.plot(xp, pred2, color='r', label='Specifying degree =3 with 4 knots')\n",
    "plt.legend()\n",
    "plt.xlim(15,85)\n",
    "plt.ylim(0,350)\n",
    "plt.xlabel('age')\n",
    "plt.ylabel('wage')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jqtRsv3Zd1kF"
   },
   "source": [
    "### Natuaral Spline\n",
    "We know that the behavior of polynomials that are fit to the data tends to be erratic near the boundaries. Such variability can be dangerous. These problems are resembled by splines, too. The polynomials fit beyond the boundary knots behave even more wildly than the corresponding global polynomials in that region. To smooth the polynomial beyond the boundary knots, we will use a special type of spline known as **Natural Spline**.\n",
    "\n",
    "A natural cubic spline adds additional constraints\n",
    "- the function is linear beyond the boundary knots. \n",
    "\n",
    "This constrains the cubic and quadratic parts there to 0, each reducing the degrees of freedom by 2. That’s 2 degrees of freedom at each of the two ends of the curve, reducing K+4 to K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xWKnf3v9eVA1",
    "outputId": "49e046a8-31cf-4735-d964-1c9e9b3e4a31"
   },
   "outputs": [],
   "source": [
    "# Generating natural cubic spline (cubic regression)\n",
    "transformed_x3 = dmatrix(\"cr(train,df = 3)\", {\"train\": train_x}, return_type='dataframe')\n",
    "fit3 = sm.GLM(train_y, transformed_x3).fit()\n",
    "\n",
    "# Prediction on validation set\n",
    "pred3 = fit3.predict(dmatrix(\"cr(valid, df=3)\", {\"valid\": valid_x}, return_type='dataframe'))\n",
    "# Calculating RMSE value\n",
    "rms = sqrt(mean_squared_error(valid_y, pred3))\n",
    "print(rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "3af2-wcaeVtY",
    "outputId": "0fab9c75-ece7-4b73-be93-18488f7a1af7"
   },
   "outputs": [],
   "source": [
    "# We will plot the graph for 70 observations only\n",
    "xp = np.linspace(valid_x.min(),valid_x.max(),70)\n",
    "pred3 = fit3.predict(dmatrix(\"cr(xp, df=3)\", {\"xp\": xp}, return_type='dataframe'))\n",
    "\n",
    "# Plot the spline\n",
    "plt.scatter(data.age, data.wage, facecolor='None', edgecolor='k', alpha=0.1)\n",
    "plt.plot(xp, pred3,color='g', label='Natural spline')\n",
    "plt.legend()\n",
    "plt.xlim(15,85)\n",
    "plt.ylim(0,350)\n",
    "plt.xlabel('age')\n",
    "plt.ylabel('wage')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rAR2_tFJnbJl"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "06_Nonparametric_regression_lesson.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
