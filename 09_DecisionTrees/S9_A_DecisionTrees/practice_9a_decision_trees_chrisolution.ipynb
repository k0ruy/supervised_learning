{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Decision Trees\n",
    "\n",
    "1. Train and fine-tune a Decision Tree for the moons' dataset.\n",
    "\n",
    "(a) Generate a moons' dataset using make_moons(n_samples=10000, noise=0.4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X, y= make_moons(n_samples=10000, noise=0.4, random_state=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "(b) Split it into a training set and a test set using train_test_split()."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "(c) Use grid search with cross-validation (with the help of the GridSearchCV class) to find good hyper-parameter values\n",
    "for a DecisionTreeClassifier. Hint: try various values for max_leaf_nodes."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(max_leaf_nodes=36, random_state=0)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "tree_parameters = {'criterion':['gini','entropy'], 'max_leaf_nodes': list(range(2, 50))}\n",
    "clf = GridSearchCV(DecisionTreeClassifier(random_state=0), tree_parameters, cv=5)\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.best_estimator_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Following the hint I optimized on the maximum number of leaf nodes, other parameters could\n",
    "also be taken into account."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "(d) Train it on the full training set using these hyper-parameters, and measure your model’s performance\n",
    "on the test set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model's accuracy score is: 0.868\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "best_tree = DecisionTreeClassifier(max_leaf_nodes=36, random_state=0)\n",
    "best_tree.fit(X_train, y_train)\n",
    "y_predicted = best_tree.predict(X_test)\n",
    "print(f\"The model's accuracy score is: {accuracy_score(y_test, y_predicted)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Grow a forest.\n",
    "\n",
    "(a) Continuing the previous exercise, generate 1; 000 subsets of the training set,\n",
    "each containing 100 instances selected randomly.\n",
    "Hint: you can use Scikit- Learn’s ShuffleSplit class for this."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "random_shuffle = ShuffleSplit(n_splits=1000, train_size=0.0134, random_state=0)\n",
    "\n",
    "X_subsets, y_subsets = {}, {}\n",
    "for i, indexes in enumerate(random_shuffle.split(X_train)):\n",
    "    X_subsets[i] = X_train[indexes[0], :]\n",
    "    y_subsets[i] = y_train[indexes[0]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "(b) Train one Decision Tree on each subset, using the best hyper-parameter values\n",
    "found above. Evaluate these 1; 000 Decision Trees on the test set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7941336\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "best_tree = DecisionTreeClassifier(max_leaf_nodes=36, random_state=0)\n",
    "scores = []\n",
    "for subset in range(len(X_subsets)):\n",
    "    best_tree.fit(X_subsets[subset], y_subsets[subset])\n",
    "    y_predict = best_tree.predict(X_test)\n",
    "    scores.append(accuracy_score(y_test, y_predict))\n",
    "\n",
    "print(np.mean(scores))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "(c) For each test set instance, generate the predictions of the 1,000 Decision\n",
    "Trees, and keep only the most frequent prediction (you can use SciPy’s mode()\n",
    "function for this). This gives you majority-vote predictions over the test set."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "\n",
    "predictions: list[int] = []\n",
    "for i in range (len(X_subsets)):\n",
    "    predictions.append(best_tree.fit(X_subsets[i], y_subsets[i]).predict(X_test))\n",
    "\n",
    "y_predict_vote, vote_count = mode(predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "(d) Evaluate these predictions on the test set. Which are the performances compared\n",
    "to the single model trained in point 1."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model's accuracy score is: 0.8692\n",
      "\n",
      "Confusion Matrix standard: \n",
      " [[1107  158]\n",
      " [ 172 1063]] \n",
      "\n",
      "Confusion Matrix voting: \n",
      " [[1103  162]\n",
      " [ 165 1070]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(f\"The model's accuracy score is: {accuracy_score(y_test, y_predict_vote.T)}\\n\")\n",
    "print(\"Confusion Matrix standard: \\n\", confusion_matrix(y_test, y_predicted),\"\\n\")\n",
    "print(\"Confusion Matrix voting: \\n\", confusion_matrix(y_test, y_predict_vote.T),\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Although the improvement is not large, we get a better result with majority voting, as expected from the class theory."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Bonus random forest just for curiosity."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_leaf_nodes=60, n_estimators=28, random_state=0)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "\n",
    "param_grid = {'max_leaf_nodes': [30, 40, 50, 60, 70, 80]}\n",
    "base_estimator = RandomForestClassifier(random_state=0)\n",
    "sh = HalvingGridSearchCV(base_estimator, param_grid, cv=5, factor=2,\n",
    "                         resource='n_estimators',max_resources=30).fit(X_train, y_train)\n",
    "best_random_forest = sh.best_estimator_\n",
    "print(best_random_forest)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model's accuracy score is: 0.8724\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_predict_best_random_forest = best_random_forest.predict(X_test)\n",
    "print(f\"The model's accuracy score is: {accuracy_score(y_test, y_predict_best_random_forest)}\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model's accuracy score is: 0.8724\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "param_grid = {'max_leaf_nodes': [30, 40, 50, 60, 70, 80]}\n",
    "base_estimator = ExtraTreesClassifier(random_state=0)\n",
    "sh = HalvingGridSearchCV(base_estimator, param_grid, cv=5, factor=2,\n",
    "                         resource='n_estimators',max_resources=30).fit(X_train, y_train)\n",
    "y_predict_extra = best_random_forest.predict(X_test)\n",
    "print(f\"The model's accuracy score is: {accuracy_score(y_test, y_predict_extra)}\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}